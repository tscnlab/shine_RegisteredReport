mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope * e2_value + p4_slope * p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
fake_data_results_2 <- rbind(fake_data_results_2,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes") %>%
summarise(mean = mean(mean_y))
print(fake_data_results_2_summary)
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
y = intercept + slope1*E2 + slope2*P4 + noise
# Importing data
mlt_data <- read.csv("VR_paper_melatonin_results.csv")
# Calculating summary statistics
mlt_data_summary <- mlt_data %>%
summarise(mean = mean(mel_supp),
sd = sd(mel_supp),
median = median(mel_supp),
iqr = IQR(mel_supp),
q1 = quantile(mel_supp, 0.25),
q3 = quantile(mel_supp, 0.75))
# We start by defining variables of our model
intercept_mean_list <- seq(0,70, by = 5)
e2_slope_mean_list <- seq(0.001, 10, by = 0.1)
p4_slope_mean_list <- seq(0.001, 10, by = 0.1)
e2_min_value <- 75.5
e2_max_value <- 2212
p4_min_value <- 0.159
p4_max_value <- 66.5
num_simulations <- 100
mlt_data_mean <- mlt_data_summary$mean
mlt_data_sd <- mlt_data_summary$sd
mlt_data_median <- mlt_data_summary$median
mlt_data_q1 <- mlt_data_summary$q1
mlt_data_q3 <- mlt_data_summary$q3
# Create empty data frame to store results
fake_data_results_2 <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope * e2_value + p4_slope * p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
fake_data_results_2 <- rbind(fake_data_results_2,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes") %>%
summarise(mean = mean(mean_y))
print(fake_data_results_2_summary)
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
# We start by defining variables of our model
intercept_mean_list <- seq(0,70, by = 5)
e2_slope_mean_list <- seq(0.001, 5, by = 0.1)
p4_slope_mean_list <- seq(0.001, 5, by = 0.1)
e2_min_value <- 75.5
e2_max_value <- 2212
p4_min_value <- 0.159
p4_max_value <- 66.5
num_simulations <- 100
mlt_data_mean <- mlt_data_summary$mean
mlt_data_sd <- mlt_data_summary$sd
mlt_data_median <- mlt_data_summary$median
mlt_data_q1 <- mlt_data_summary$q1
mlt_data_q3 <- mlt_data_summary$q3
# Create empty data frame to store results
fake_data_results_2 <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope * e2_value + p4_slope * p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
fake_data_results_2 <- rbind(fake_data_results_2,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes") %>%
summarise(mean = mean(mean_y))
print(fake_data_results_2_summary)
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
View(fake_data_results_2)
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes")
View(fake_data_results_2_summary)
e2_slope_mean_list
View(mlt_data_summary)
# We start by defining variables of our model
intercept_mean_list <- seq(0, 100, by = 5)
e2_slope_mean_list <- c(
seq(0.001, 0.009, length.out = 10),  # values in 0.001–0.009
seq(0.01, 0.09, length.out = 10),    # values in 0.01–0.09
seq(0.1, 0.9, length.out = 10),      # values in 0.1–0.9
seq(1, 9, length.out = 10),          # values in 1–9
seq(10, 100, length.out = 10)        # values in 10–100
)
p4_slope_mean_list <- c(
seq(0.001, 0.009, length.out = 10),
seq(0.01, 0.09, length.out = 10),
seq(0.1, 0.9, length.out = 10),
seq(1, 9, length.out = 10),
seq(10, 100, length.out = 10)
)
e2_min_value <- 75.5
e2_max_value <- 2212
p4_min_value <- 0.159
p4_max_value <- 66.5
num_simulations <- 100
mlt_data_mean <- mlt_data_summary$mean
mlt_data_sd <- mlt_data_summary$sd
mlt_data_median <- mlt_data_summary$median
mlt_data_q1 <- mlt_data_summary$q1
mlt_data_q3 <- mlt_data_summary$q3
p4_slope_mean_list
# Create empty data frame to store results
fake_data_results_2 <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope * e2_value + p4_slope * p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
fake_data_results_2 <- rbind(fake_data_results_2,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes")
print(fake_data_results_2_summary)
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
View(fake_data_results_2_summary)
intercept_mean_list
e2_slope_mean_list
fake_data_results_2_summary <- fake_data_results_2 %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
max_p4 = max(p4_slope_mean))
View(fake_data_results_2_summary)
# We start by defining variables of our model
# Intercept
intercept_mean_list <- seq(0, 100, by = 5)
#E2 slope values
e2_slope_mean_list <- c(
seq(0.001, 0.009, length.out = 10),  # values in 0.001–0.009
seq(0.01, 0.09, length.out = 10),    # values in 0.01–0.09
seq(0.1, 0.9, length.out = 10),      # values in 0.1–0.9
seq(1, 9, length.out = 10),          # values in 1–9
seq(10, 100, length.out = 10)        # values in 10–100
)
#P4 slope values
p4_slope_mean_list <- c(
seq(0.001, 0.009, length.out = 10),
seq(0.01, 0.09, length.out = 10),
seq(0.1, 0.9, length.out = 10),
seq(1, 9, length.out = 10),
seq(10, 100, length.out = 10)
)
# E2 and P4 values (expressed in pmol/L for E2 and nmol/L for P4)
e2_min_value <- 75.5
e2_max_value <- 2212
p4_min_value <- 0.159
p4_max_value <- 66.5
num_simulations <- 100
# Extract known mlt values from mlt_data_summary
mlt_data_mean <- mlt_data_summary$mean
mlt_data_sd <- mlt_data_summary$sd
mlt_data_median <- mlt_data_summary$median
mlt_data_q1 <- mlt_data_summary$q1
mlt_data_q3 <- mlt_data_summary$q3
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Centering E2 and P4 - needed because the given values are on different scales
e2_centered <- e2_value - mean(c(e2_min_value, e2_max_value))
p4_centered <- p4_value - mean(c(p4_min_value, p4_max_value))
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope*e2_centered + p4_slope*p4_centered + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
simulated_data_results <- rbind(simulated_data_results,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
simulated_data_results <- simulated_data_results %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
max_p4 = max(p4_slope_mean))
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
View(simulated_data_results)
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Centering E2 and P4 - needed because the given values are on different scales
e2_centered <- e2_value - mean(c(e2_min_value, e2_max_value))
p4_centered <- p4_value - mean(c(p4_min_value, p4_max_value))
# Noise ~ N(0, 5)
noise <- rnorm(1, mean = 0, sd = 5)
# Intercept ~ N(intercept_mean, 10% of intercept_mean)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
# Slopes ~ N(slope_mean, 10% of slope_mean)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
# Model
y[simulation] <- intercept + e2_slope*e2_centered + p4_slope*p4_centered + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
# Store results
simulated_data_results <- rbind(simulated_data_results,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
simulated_data_results_summary <- simulated_data_results %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
max_p4 = max(p4_slope_mean))
# Save results as a csv that we can look at
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)
View(simulated_data_results)
View(simulated_data_results_summary)
simulated_data_results_summary <- simulated_data_results %>%
filter(accepted == "yes")
View(simulated_data_results_summary)
simulated_data_results_summary <- simulated_data_results %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
max_p4 = max(p4_slope_mean))
View(simulated_data_results_summary)
ggplot(simulated_data_results %>% filter(accepted == "yes"), aes(x = e2_slope_mean, y = p4_slope_mean, color = intercept_mean)) +
geom_point() +
scale_color_viridis_c() +
labs(title = "Accepted Parameter Combinations",
x = "E2 Slope Mean",
y = "P4 Slope Mean",
color = "Intercept")
simulated_data_results_summary <- simulated_data_results %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
median_e2 = median(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
max_p4 = max(p4_slope_mean))
View(simulated_data_results_summary)
simulated_data_results_summary <- simulated_data_results %>%
filter(accepted == "yes") %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
median_e2 = median(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
median_p4 = median(p4_slope_mean),
max_p4 = max(p4_slope_mean))
View(simulated_data_results_summary)
install.packages("GGally")
GGally::ggpairs(simulated_data_results[simulated_data_results$accepted == "yes",
c("intercept_mean", "e2_slope_mean", "p4_slope_mean")])
library(ggplot2)
ggplot(accepted_params, aes(x = intercept_mean)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = e2_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "salmon", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = p4_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "lightgreen", color = "black") +
theme_minimal()
accepted_params <- simulated_data_results %>%
filter(accepted == "yes")
library(ggplot2)
ggplot(accepted_params, aes(x = intercept_mean)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = e2_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "salmon", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = p4_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "lightgreen", color = "black") +
theme_minimal()
quantile(accepted_params$p4_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$intercept_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$p4_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$intercept_mean, probs = c(0.1, 0.9))
GGally::ggpairs(simulated_data_results[simulated_data_results$accepted == "yes",
c("intercept_mean", "e2_slope_mean", "p4_slope_mean")])
accepted_params <- simulated_data_results %>%
filter(accepted == "yes")
library(ggplot2)
ggplot(accepted_params, aes(x = intercept_mean)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = e2_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "salmon", color = "black") +
theme_minimal()
ggplot(accepted_params, aes(x = p4_slope_mean)) +
geom_histogram(binwidth = 0.1, fill = "lightgreen", color = "black") +
theme_minimal()
quantile(accepted_params$intercept_mean, probs = c(0.1, 0.9))
quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
quantile(accepted_params$p4_slope_mean, probs = c(0.1, 0.9))
# Get 10th and 90th percentiles to define "central" range
intercept_range <- quantile(accepted_params$intercept_mean, probs = c(0.1, 0.9))
e2_slope_range <- quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
p4_slope_range <- quantile(accepted_params$p4_slope_mean, probs = c(0.1, 0.9))
