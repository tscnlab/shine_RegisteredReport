)
View(mlt_data_standardised)
# We start by defining variables of our model
# Intercept in standardised scale (since now melatonin data does not go from 0 to 100)
intercept_mean_list <- seq(-1, 1, by = 0.5)
#E2 slope values in standardised scale
e2_slope_mean_list <- seq(-2, 2, by = 0.5)
#P4 slope values in standardised scale
p4_slope_mean_list <- seq(-2, 2, by = 0.5)
# E2 and P4 values (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Number of simulations
num_simulations <- 100
# Extract known mlt values from mlt_data_standardised_summary
mlt_data_standardised_q1 <- mlt_data_standardised_summary$q1
mlt_data_standardised_q3 <- mlt_data_standardised_summary$q3
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, sd = 0.1)
noise <- rnorm(1, mean = 0, sd = 0.7)
# Intercept ~ N(intercept_mean, sd = 0.1)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.1)
# Slopes ~ N(slope_mean, sd = 0.1)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1)
# Model
y[simulation] <- intercept + e2_slope*e2_value + p4_slope*p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_standardised_q1 & mean_y <= mlt_data_standardised_q3, "yes", "no")
# Store results
simulated_data_results <- rbind(simulated_data_results,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
# Filter dataset to only accept values within mlt_data q1 and q3
accepted_params <- simulated_data_results %>%
filter(accepted == "yes")
# Summary of accepted paramters
accepted_params_summary <- accepted_params %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
median_e2 = median(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
median_p4 = median(p4_slope_mean),
max_p4 = max(p4_slope_mean))
write.csv(accepted_params, "informed_parameters.csv", row.names = FALSE)
library(tidyverse)
library(BayesFactor)
set.seed(20250602)
informed_parameters <- read.csv("informed_parameters.csv")
# Keep only cols of interest
informed_parameters <- informed_parameters %>%
select(intercept_mean, e2_slope_mean, p4_slope_mean)
set.seed(20250602)
# Fixed participant number, dictated by resource limitations
n_ids <- 12
# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)
# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)
# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.1
e2_slope_sd <- 0.1
p4_slope_sd <- 0.1
# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Define number of simulations to run
num_simulations <- 5
# Define threshold for Bayes Factor
bf_threshold <- 3
set.seed(20250602)
# Create empty data frame to store simulated data
bfda_simulated_data <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
TPR = numeric()
)
# Create a for loop to iterate through the possible combinations of parameters (intercept, e2 slopes, and p4 slope)
for (row in 1:nrow(informed_parameters)) { # looping through each row of the informed_parameter dataframe
# Store BFs for simulations
bf_list <- numeric(num_simulations)
# Run simulations: for each combination, repeat the simulation 1000 times
for (simulation in seq_len(num_simulations)) {
print(paste0("Row:", row))
print(paste0("Simulation:", simulation))
# Sample intercept and slopes from normal distribution of defined parameters
intercept <- rnorm(n_ids, mean = informed_parameters$intercept_mean[row], sd = intercept_sd)
e2_slope <- rnorm(n_ids, mean = informed_parameters$e2_slope_mean[row], sd = e2_slope_sd)
p4_slope <- rnorm(n_ids, mean = informed_parameters$p4_slope_mean[row], sd = p4_slope_sd)
# Simulate data for n_ids individuals
# We are making the assumption that E2 and P4 are independent (for simplicity)
sim_data <- data.frame(
id = factor(rep(1:n_ids, each = 4)),
e2_value = runif((4*n_ids), e2_min_value, e2_max_value),
p4_value = runif((4*n_ids), p4_min_value, p4_max_value)
)
# Create values for y by solving the equation and add noise
sim_data$y <- intercept[sim_data$id] +
e2_slope[sim_data$id]*sim_data$e2_value + # e2 slope * e2 value for given id
p4_slope[sim_data$id]*sim_data$p4_value + # p4 slope * p4 value for given id
rnorm(n_ids*4, mean = 0, sd = 0.7) # noise ~ N(0, sd=0.1), for each experiment
print(paste0("Sim data row",nrow(sim_data))) # print number of rows for sim_data
# Compute Bayes Factor for full model, with predictors being e2 and p4 levels
set.seed(20250602)
bf_full <- BayesFactor::lmBF(y ~ e2_value + p4_value + id +id:e2_value + id:p4_value,
data = sim_data,
whichRandom = "id",
progress = FALSE) # fitting individual slope and intercept for each id
# This function already calculates the ratio between the full model and a model where the intercept is the grand mean
# Compute the Bayes Factor for the null model, with predictor being the id variation
set.seed(20250602)
bf_only_intercept <- BayesFactor::lmBF(y ~ id,
data = sim_data,
whichRandom = "id",
progress = FALSE) # fitting a different intercept for each id
# This function calculates the ratio between a model where the intercept is different for each id compared to a model where the intercept in the grand mean
# Take ratio of these two models, meaning the models where intercept is the grand mean cancel each other out
# So we are effectively taking a ratio between the full model and a model where the intercept is different for id
bf_ratio <- bf_full/bf_only_intercept
print(bf_full)
print(bf_only_intercept)
print(bf_ratio)
# Extract BF value from bf_ratio
bf_list[simulation] <- as.numeric(BayesFactor::extractBF(bf_ratio)$bf)
}
# Compute True Positive Rate (TPR)
TPR <- as.numeric(sum(bf_list > bf_threshold) / length(bf_list))
# Store in results
bfda_simulated_data <- rbind(bfda_simulated_data,
data.frame(
intercept_mean = informed_parameters$intercept_mean[row],
e2_slope_mean = informed_parameters$e2_slope_mean[row],
p4_slope_mean = informed_parameters$p4_slope_mean[row],
TPR = TPR)
)
}
View(bfda_simulated_data)
library(ggplot2)
ggplot(bfda_simulated_data, aes(x = e2_slope_mean, y = p4_slope_mean, fill = TPR)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
labs(title = "TPR across slope combinations",
x = "E2 Slope Mean",
y = "P4 Slope Mean",
fill = "TPR") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
# We start by defining variables of our model
# Intercept in standardised scale (since now melatonin data does not go from 0 to 100)
intercept_mean_list <- seq(-1, 1, by = 0.5)
#E2 slope values in standardised scale
e2_slope_mean_list <- seq(-1, 1, by = 0.1)
#P4 slope values in standardised scale
p4_slope_mean_list <- seq(-1, 1, by = 0.1)
# E2 and P4 values (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Number of simulations
num_simulations <- 100
# Extract known mlt values from mlt_data_standardised_summary
mlt_data_standardised_q1 <- mlt_data_standardised_summary$q1
mlt_data_standardised_q3 <- mlt_data_standardised_summary$q3
library(tidyverse)
# Importing data
mlt_data <- read.csv("VR_paper_melatonin_results.csv")
# Calculating summary statistics on raw data
mlt_raw_data_summary <- mlt_data %>%
summarise(mean = mean(mel_supp),
sd = sd(mel_supp),
median = median(mel_supp),
iqr = IQR(mel_supp),
q1 = quantile(mel_supp, 0.25),
q3 = quantile(mel_supp, 0.75))
# Standardise raw data so that it falls between -1 and 1
mlt_data_standardised <- mlt_data %>%
mutate(mel_supp_standardised = (mel_supp - mean(mel_supp))/sd(mel_supp)
)
# Calculating summary statistics on standardised data
mlt_data_standardised_summary <- mlt_data_standardised %>%
summarise(mean = mean(mel_supp_standardised),
sd = sd(mel_supp_standardised),
median = median(mel_supp_standardised),
q1 = quantile(mel_supp_standardised, 0.25),
q3 = quantile(mel_supp_standardised, 0.75)
)
# We start by defining variables of our model
# Intercept in standardised scale (since now melatonin data does not go from 0 to 100)
intercept_mean_list <- seq(-1, 1, by = 0.5)
#E2 slope values in standardised scale
e2_slope_mean_list <- seq(-1, 1, by = 0.1)
#P4 slope values in standardised scale
p4_slope_mean_list <- seq(-1, 1, by = 0.1)
# E2 and P4 values (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Number of simulations
num_simulations <- 100
# Extract known mlt values from mlt_data_standardised_summary
mlt_data_standardised_q1 <- mlt_data_standardised_summary$q1
mlt_data_standardised_q3 <- mlt_data_standardised_summary$q3
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, sd = 0.1)
noise <- rnorm(1, mean = 0, sd = 0.3)
# Intercept ~ N(intercept_mean, sd = 0.1)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.3)
# Slopes ~ N(slope_mean, sd = 0.1)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.3)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.3)
# Model
y[simulation] <- intercept + e2_slope*e2_value + p4_slope*p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_standardised_q1 & mean_y <= mlt_data_standardised_q3, "yes", "no")
# Store results
simulated_data_results <- rbind(simulated_data_results,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
# Filter dataset to only accept values within mlt_data q1 and q3
accepted_params <- simulated_data_results %>%
filter(accepted == "yes")
# Summary of accepted paramters
accepted_params_summary <- accepted_params %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
median_e2 = median(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
median_p4 = median(p4_slope_mean),
max_p4 = max(p4_slope_mean))
# We start by defining variables of our model
# Intercept in standardised scale (since now melatonin data does not go from 0 to 100)
intercept_mean_list <- seq(-1, 1, by = 0.5)
#E2 slope values in standardised scale
e2_slope_mean_list <- seq(-1, 1, by = 0.3)
#P4 slope values in standardised scale
p4_slope_mean_list <- seq(-1, 1, by = 0.3)
# E2 and P4 values (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Number of simulations
num_simulations <- 100
# Extract known mlt values from mlt_data_standardised_summary
mlt_data_standardised_q1 <- mlt_data_standardised_summary$q1
mlt_data_standardised_q3 <- mlt_data_standardised_summary$q3
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
mean_y = numeric(),
sd_y = numeric(),
accepted = factor())
for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
# Simulate 100 samples of y for each parameter combination
y <- numeric(num_simulations)
for (simulation in seq_len(num_simulations)) {
# Sample E2 and P4 from uniform distribution
e2_value <- runif(1, e2_min_value, e2_max_value)
p4_value <- runif(1, p4_min_value, p4_max_value)
# Noise ~ N(0, sd = 0.1)
noise <- rnorm(1, mean = 0, sd = 0.3)
# Intercept ~ N(intercept_mean, sd = 0.1)
intercept <- rnorm(1, mean = intercept_mean, sd = 0.3)
# Slopes ~ N(slope_mean, sd = 0.1)
e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.3)
p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.3)
# Model
y[simulation] <- intercept + e2_slope*e2_value + p4_slope*p4_value + noise
}
# Calculate summary stats of y
mean_y <- mean(y)
sd_y <- sd(y)
# Determine if the mean of y is within q1 and q3 of the known melatonin data
accepted <- ifelse(mean_y >= mlt_data_standardised_q1 & mean_y <= mlt_data_standardised_q3, "yes", "no")
# Store results
simulated_data_results <- rbind(simulated_data_results,
data.frame(intercept_mean = intercept_mean,
e2_slope_mean = e2_slope_mean,
p4_slope_mean = p4_slope_mean,
mean_y = mean_y,
sd_y = sd_y,
accepted = factor(accepted)))
}
}
}
# Filter dataset to only accept values within mlt_data q1 and q3
accepted_params <- simulated_data_results %>%
filter(accepted == "yes")
# Summary of accepted paramters
accepted_params_summary <- accepted_params %>%
summarise(min_intercept = min(intercept_mean),
max_intercept = max(intercept_mean),
min_e2 = min(e2_slope_mean),
median_e2 = median(e2_slope_mean),
max_e2 = max(e2_slope_mean),
min_p4 = min(p4_slope_mean),
median_p4 = median(p4_slope_mean),
max_p4 = max(p4_slope_mean))
GGally::ggpairs(simulated_data_results[simulated_data_results$accepted == "yes",
c("intercept_mean", "e2_slope_mean", "p4_slope_mean")])
write.csv(accepted_params, "informed_parameters.csv", row.names = FALSE)
set.seed(20250602)
# Fixed participant number, dictated by resource limitations
n_ids <- 12
# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)
# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)
# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.3
e2_slope_sd <- 0.3
p4_slope_sd <- 0.3
# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Define number of simulations to run
num_simulations <- 100
# Define threshold for Bayes Factor
bf_threshold <- 3
library(tidyverse)
library(BayesFactor)
set.seed(20250602)
informed_parameters <- read.csv("informed_parameters.csv")
# Keep only cols of interest
informed_parameters <- informed_parameters %>%
select(intercept_mean, e2_slope_mean, p4_slope_mean)
set.seed(20250602)
# Fixed participant number, dictated by resource limitations
n_ids <- 12
# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)
# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)
# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.3
e2_slope_sd <- 0.3
p4_slope_sd <- 0.3
# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1
# Define number of simulations to run
num_simulations <- 100
# Define threshold for Bayes Factor
bf_threshold <- 3
set.seed(20250602)
# Create empty data frame to store simulated data
bfda_simulated_data <- data.frame(intercept_mean = numeric(),
e2_slope_mean = numeric(),
p4_slope_mean = numeric(),
TPR = numeric()
)
# Create a for loop to iterate through the possible combinations of parameters (intercept, e2 slopes, and p4 slope)
for (row in 1:nrow(informed_parameters)) { # looping through each row of the informed_parameter dataframe
# Store BFs for simulations
bf_list <- numeric(num_simulations)
# Run simulations: for each combination, repeat the simulation 1000 times
for (simulation in seq_len(num_simulations)) {
print(paste0("Row:", row))
print(paste0("Simulation:", simulation))
# Sample intercept and slopes from normal distribution of defined parameters
intercept <- rnorm(n_ids, mean = informed_parameters$intercept_mean[row], sd = intercept_sd)
e2_slope <- rnorm(n_ids, mean = informed_parameters$e2_slope_mean[row], sd = e2_slope_sd)
p4_slope <- rnorm(n_ids, mean = informed_parameters$p4_slope_mean[row], sd = p4_slope_sd)
# Simulate data for n_ids individuals
# We are making the assumption that E2 and P4 are independent (for simplicity)
sim_data <- data.frame(
id = factor(rep(1:n_ids, each = 4)),
e2_value = runif((4*n_ids), e2_min_value, e2_max_value),
p4_value = runif((4*n_ids), p4_min_value, p4_max_value)
)
# Create values for y by solving the equation and add noise
sim_data$y <- intercept[sim_data$id] +
e2_slope[sim_data$id]*sim_data$e2_value + # e2 slope * e2 value for given id
p4_slope[sim_data$id]*sim_data$p4_value + # p4 slope * p4 value for given id
rnorm(n_ids*4, mean = 0, sd = 0.3) # noise ~ N(0, sd=0.3), for each experiment
print(paste0("Sim data row",nrow(sim_data))) # print number of rows for sim_data
# Compute Bayes Factor for full model, with predictors being e2 and p4 levels
set.seed(20250602)
bf_full <- BayesFactor::lmBF(y ~ e2_value + p4_value + id +id:e2_value + id:p4_value,
data = sim_data,
whichRandom = "id",
progress = FALSE) # fitting individual slope and intercept for each id
# This function already calculates the ratio between the full model and a model where the intercept is the grand mean
# Compute the Bayes Factor for the null model, with predictor being the id variation
set.seed(20250602)
bf_only_intercept <- BayesFactor::lmBF(y ~ id,
data = sim_data,
whichRandom = "id",
progress = FALSE) # fitting a different intercept for each id
# This function calculates the ratio between a model where the intercept is different for each id compared to a model where the intercept in the grand mean
# Take ratio of these two models, meaning the models where intercept is the grand mean cancel each other out
# So we are effectively taking a ratio between the full model and a model where the intercept is different for id
bf_ratio <- bf_full/bf_only_intercept
print(bf_full)
print(bf_only_intercept)
print(bf_ratio)
# Extract BF value from bf_ratio
bf_list[simulation] <- as.numeric(BayesFactor::extractBF(bf_ratio)$bf)
}
# Compute True Positive Rate (TPR)
TPR <- as.numeric(sum(bf_list > bf_threshold) / length(bf_list))
# Store in results
bfda_simulated_data <- rbind(bfda_simulated_data,
data.frame(
intercept_mean = informed_parameters$intercept_mean[row],
e2_slope_mean = informed_parameters$e2_slope_mean[row],
p4_slope_mean = informed_parameters$p4_slope_mean[row],
TPR = TPR)
)
}
# Plot y vs e2_value coloured by id
ggplot(sim_data, aes(x = e2_value, y = y, color = id)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
labs(title = "Random slopes and intercept check for E2",
x = "e2_value",
y = "Melatonin suppression") +
theme_minimal()
# Plot y vs p4_value coloured by id
ggplot(sim_data, aes(x = p4_value, y = y, color = id)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
labs(title = "Random slopes and intercept check for P4",
x = "p4_value",
y = "Melatonin suppression") +
theme_minimal()
library(ggplot2)
ggplot(bfda_simulated_data, aes(x = e2_slope_mean, y = p4_slope_mean, fill = TPR)) +
geom_tile(color = "white") +
scale_fill_gradient(low = "blue", high = "red") +
labs(title = "TPR across slope combinations",
x = "E2 Slope Mean",
y = "P4 Slope Mean",
fill = "TPR") +
theme_minimal()
View(informed_parameters)
View(sim_data)
View(sim_data)
View(bfda_simulated_data)
bf_list
