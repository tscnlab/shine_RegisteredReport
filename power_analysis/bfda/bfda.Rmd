# Aim of this script 
This script aims to perform a Bayes Factor Design Analysis (BFDA) for a fixed-n sample. The rationale for this exercise is the need to perform a power analysis for a study on the effect of the menstrual cycle on melatonin suppression, which is currently being designed.

## Why BFDA for power analysis?
The advantage of benefit over frequentist power analysis is that it allows to "plan for compelling evidence". The frequentist hypothesis testing (NSHT) approach does not inform us on the expected strength of evidence of our results, and relies on estimates of effect sizes. This is problematic because extracting effect sizes from the literature is tricky, in the sense that it is rare to find an effect size estimate from a study which had a design very similar to the one we are planning to perform. On the other hand, In fact, the BFDA approach to power analysis allows to answer the question: which evidence strength can I expect for a specific research design? This is quantified with a metric called Bayes Factor (BF). Typically, BFs that are smaller than 1/10 or larger than 10 are counted as strong evidence for the null and alternative hypothesis, respectively.

One implication of BFDA is that a specific study design and model of how the data will be interpreted has to be formulated prior to data collection. In fact, BFDA is performed during the design phase of a study.

## BFDA for the SHINE (sex Steroid Hormones Influence on the Neuroendocrine Effects of light) project
In this study, we are investigating the effect of menstrual cycle phase on melatonin suppression by light at night. Our hypotheses are the following:
H1: In naturally cycling individuals, we hypothesise an effect of menstrual cycle phase on melatonin suppression outcomes.
H0: No effect of menstrual cycle phase on melatonin suppression outcomes.
We believe that the following model described the data:
- Full model: Melatonin AUC relative to dark AUC = β0 +β1 Menstrual phase + β2 (1|participant) + β3 (1|menstrual phase)
- Null model: Melatonin AUC relative to dark AUC = β0 + β1 (1|participant)

The type of BFDA we want to perform in this study is a fixed-n design. This is because we know that we can only have a maximum of n=12 naturally cycling participants for resource and time constraints. Hence, the BFDA can help us to answer this questions:
1. Given a sample size of N=12 and expected population effect size, which Bayes Factors can I expect?
2. What sample size do I need to have to obtain true positive or true negative evidence with a certain probability?

### Fixed-n BFDA workflow
The general workflow we will follow:
1. Generate a full model that you think explains the data, and a related null model
2. Assume a population with certain properties
3. Repeatedly draw random samples from this population
4. Compute the BF for each sample


#### Requirements
- We define a model for the data we are interested in collecting in our experiment. For example y = a + b*x. Let's imagine that y is melatonin suppression response and x is menstrual cycle phase. 
- We define a sample size of n=12
- We assume that a and b have a normal distribution with mean mean_a (5 possible values) and mean_b (5 possible values)
- We assume that the sd of a and the sd of b are fixed, i.e. sd_a = 0.1, sd_b = 0.1
- We also define that x is menstrual cycle phase, so it can only assume 4 values

Model of interest to test CH3a:
melatonin suppression = E2 levels + P4 levels + (E2 + P4 | PID), where E2 = estradiol levels, P4 = progesterone levels, and PID = participant ID.

## Importing the informed parameters
These have been calculated in the previous script (informed_data_simulation.Rmd)
```{r}
library(tidyverse)
library(BayesFactor)


informed_parameters <- read.csv("informed_parameters.csv")

# Keep only cols of interest
informed_parameters <- informed_parameters %>%
  select(intercept_mean, e2_slope_mean, p4_slope_mean)
```

## Defining the parameters for bfda model 
Our full model is:
y = intercept + e2_slope * e2_value + p4_slope * p4_value + noise
```{r}


# Fixed participant number, dictated by resource limitations
n_ids <- 12 

# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)

# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)

# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.3
e2_slope_sd <- 0.3
p4_slope_sd <- 0.3

# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1

# Define number of simulations to run
num_simulations <- 10

# Define threshold for Bayes Factor 
bf_threshold <- 3
```

### Running the simulations and generating data
We will run 1000 simulations for each combination of mean_a and mean_b. For each simulation, we will generate data for each participant by solving the equation y=a + bx. We will then compute the Bayes Factor for each simulation. We will then calculate the True Positive Rate (TPR) for each combination of mean_a and mean_b. The TPR is defined as the number of BFs that are greater than the threshold divided by the total number of BFs. We will store the results in a dataframe with columns mean_a, mean_b, and TPR. We will then plot this as a heatmap with the x-axis as mean_a, the y-axis as mean_b, and each cell containing the TPR. Fake code as follows:
```{r}
# for each of the 10 mean_a in means_a
#   for each of the 10 mean_b in means_b
#     Run 1000 simulations of the following
#       for each id in n_ids (12)
#         for each of the 4 values of x:
#           #generate data by solving the equation y=a + bx
#           y = rnrom(1, mean_a, sd_a) + rnorm(1, mean_b, sd_b)*x #sampling a and b from their normal distribution
#       get the BF for this one simulation (BayesFactor package compares automatically to identical simulation for the null model, i.e. where the mean_a is 0)
#     get the 1000 BFs
#     Calculate the TPR for that combination of mean_a and mean_b #there will be 100 combinations (10x10), (n bf values > threshold/number of total BFs, in this case 1000) - store this is a df where we have mean_a, mean_b, and TPR as cols 
    
# Plot this as a heatmap with x axis = mean_a, y axis = mean b, and each cell containing the TPR
```

Real code
```{r}
set.seed(20250602)

# Create empty data frame to store simulated data 
bfda_simulated_data <- data.frame(intercept_mean = numeric(),
                                  e2_slope_mean = numeric(),
                                  p4_slope_mean = numeric(),
                                  TPR = numeric()
                                  )

# Create an empty dataframe to store all BFs
bfda_all_bfs <- data.frame(
  row = numeric(),
  simulation = numeric(),
  intercept_mean = numeric(),
  e2_slope_mean = numeric(),
  p4_slope_mean = numeric(),
  BF = numeric()
)

# Create a for loop to iterate through the possible combinations of parameters (intercept, e2 slopes, and p4 slope)

for (row in 1:nrow(informed_parameters)) { # looping through each row of the informed_parameter dataframe
    
  # Store BFs for simulations
    bf_list <- numeric(num_simulations)  
    
    # Run simulations: for each combination, repeat the simulation 1000 times 
    for (simulation in seq_len(num_simulations)) {
      
      print(paste0("Row:", row))
      print(paste0("Simulation:", simulation))
      
      # Sample intercept and slopes from normal distribution of defined parameters
      intercept <- rnorm(n_ids, mean = informed_parameters$intercept_mean[row], sd = intercept_sd)
      e2_slope <- rnorm(n_ids, mean = informed_parameters$e2_slope_mean[row], sd = e2_slope_sd)
      p4_slope <- rnorm(n_ids, mean = informed_parameters$p4_slope_mean[row], sd = p4_slope_sd)
      
      # Simulate data for n_ids individuals
      # We are making the assumption that E2 and P4 are independent (for simplicity)
      sim_data <- data.frame(
        id = factor(rep(1:n_ids, each = 4)),
        e2_value = runif((4*n_ids), e2_min_value, e2_max_value),
        p4_value = runif((4*n_ids), p4_min_value, p4_max_value)
        )
      
      # Create values for y by solving the equation and add noise
      sim_data$y <- intercept[sim_data$id] +
        e2_slope[sim_data$id]*sim_data$e2_value + # e2 slope * e2 value for given id
        p4_slope[sim_data$id]*sim_data$p4_value + # p4 slope * p4 value for given id
        rnorm(n_ids*4, mean = 0, sd = 0.3) # noise ~ N(0, sd=0.3), for each experiment 
      
      print(paste0("Sim data row",nrow(sim_data))) # print number of rows for sim_data
      

      # Compute Bayes Factor for full model, with predictors being e2 and p4 levels
      bf_full <- BayesFactor::lmBF(y ~ e2_value + p4_value + id,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting individual slope and intercept for each id 
      # This function already calculates the ratio between the full model and a model where the intercept is the grand mean
      
    

      # Compute the Bayes Factor for the null model, with predictor being the id variation
      bf_only_intercept <- BayesFactor::lmBF(y ~ id,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting a different intercept for each id
      # This function calculates the ratio between a model where the intercept is different for each id compared to a model where the intercept in the grand mean 
      
      # Take ratio of these two models, meaning the models where intercept is the grand mean cancel each other out
      # So we are effectively taking a ratio between the full model and a model where the intercept is different for id
      bf_ratio <- bf_full/bf_only_intercept
      
      print(bf_full)
      print(bf_only_intercept)
      print(bf_ratio)
      
      # Extract BF value from bf_ratio
      bf_numeric <- as.numeric(BayesFactor::extractBF(bf_ratio)$bf) 
      bf_list[simulation] <- bf_numeric
      
      # Store each BF with its parameters
      bfda_all_bfs <- rbind(
        bfda_all_bfs,
        data.frame(
        row = row,
        simulation = simulation,
        intercept_mean = informed_parameters$intercept_mean[row],
        e2_slope_mean = informed_parameters$e2_slope_mean[row],
        p4_slope_mean = informed_parameters$p4_slope_mean[row],
        BF = bf_numeric
      )
    )
      
  }
    
  # Compute True Positive Rate (TPR)
  TPR <- sum(bf_list > bf_threshold) / num_simulations
  
  # Store in results
  bfda_simulated_data <- rbind(bfda_simulated_data,
                               data.frame(
                               intercept_mean = informed_parameters$intercept_mean[row],
                               e2_slope_mean = informed_parameters$e2_slope_mean[row],
                               p4_slope_mean = informed_parameters$p4_slope_mean[row],
                               TPR = TPR)
                              )
}

```

# Check that the data for each simulation is different - need to simulate 100 different experiments 
- Check that the parameter combination is different for the 100 simulations with the same parameter combination (see line 130)
- Store BFs for each simulation combination 



## Visual check to ensure that we did create random intercepts and slopes for E2 and P4
```{r}
# Plot y vs e2_value coloured by id
ggplot(sim_data, aes(x = e2_value, y = y, color = id)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
  labs(title = "Random slopes and intercept check for E2",
       x = "e2_value",
       y = "Melatonin suppression") +
  theme_minimal()

# Plot y vs p4_value coloured by id
ggplot(sim_data, aes(x = p4_value, y = y, color = id)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
  labs(title = "Random slopes and intercept check for P4",
       x = "p4_value",
       y = "Melatonin suppression") +
  theme_minimal()
```

## Checking TPR as a function of parameters

```{r}
library(ggplot2)

ggplot(bfda_simulated_data, aes(x = e2_slope_mean, y = p4_slope_mean, fill = TPR)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "blue", high = "red") +
  labs(title = "TPR across slope combinations",
       x = "E2 Slope Mean",
       y = "P4 Slope Mean",
       fill = "TPR") +
  theme_minimal()

```
```{r}
hist(bf_list, breaks = 300, main = "Bayes Factors for mid-range slopes", xlab = "BF")
abline(v = bf_threshold, col = "red")

```


```{r}
# Plot heatmap
ggplot(bfda_simulated_data,aes(x=e2_slope_mean,y=p4_slope_mean))+
  geom_tile(aes(fill=TPR), colour = "black")+
  geom_text(aes(label=TPR), colour = "white") +
  labs(title = "True positive rate for different means of a and b parameters",
       x = "E2 slpe mean",
       y = "P4 slope mean") +
  coord_fixed(ratio=1) + 
  theme(aspect.ratio = 1)

```


## Unsure about
- whichRandom parameter of lmBF: does it fit a different intercept and slope to the specified variable (i.e. in our case ID), or does it just add ID as an additional predictor?
- should we change the setting for prior distribution of fixed effects and slope effects


## Next steps
- Ensure TPR is actually computing he TPR of the 1000 simulations ith the same parameter combination 
- Play around with values of means of slopes and noise in both this script and informed_data_simulation script


### Suggestions for improvement
```{r}
# If you want to write this code more generally for a given model
# Define a function to act as your model, taking in the parameters
# model_func <- function(a,b,c,d,e,f,g,x) {
#   y <- #model, for example a + b*x
#   return y

# Define the results with all combinations of your parameter means (and sds if you cycle over them)

# results <- expand.grid(mean_a = means_a, mean_b = means_b)
# results$TPR <- NA

#instead of looping over the means (for mean_a in means_a, for mean_b in means_b, etc.) loop over the rows
# for row in results$rows {
#   mean_a <- row$mean_a
#   mean_b <- row$mean_b  ..... etc.

    #instead of writing the function again, just call the model_func you defined above.
    # sim_data$y <- model_func(a,b,x) + noise
# }
```

