# Aim of this script 
This script aims to perform a Bayes Factor Design Analysis (BFDA) for a fixed-n sample. The rationale for this exercise is the need to perform a power analysis for a study on the effect of the menstrual cycle on melatonin suppression, which is currently being designed.

## Why BFDA for power analysis?
The advantage of benefit over frequentist power analysis is that it allows to "plan for compelling evidence". The frequentist hypothesis testing (NSHT) approach does not inform us on the expected strength of evidence of our results, and relies on estimates of effect sizes. This is problematic because extracting effect sizes from the literature is tricky, in the sense that it is rare to find an effect size estimate from a study which had a design very similar to the one we are planning to perform. On the other hand, In fact, the BFDA approach to power analysis allows to answer the question: which evidence strength can I expect for a specific research design? This is quantified with a metric called Bayes Factor (BF). Typically, BFs that are smaller than 1/10 or larger than 10 are counted as strong evidence for the null and alternative hypothesis, respectively.

One implication of BFDA is that a specific study design and model of how the data will be interpreted has to be formulated prior to data collection. In fact, BFDA is performed during the design phase of a study.

## BFDA for the SHINE (sex Steroid Hormones Influence on the Neuroendocrine Effects of light) project
In this study, we are investigating the effect of menstrual cycle phase on melatonin suppression by light at night. Our hypotheses are the following:
H1: In naturally cycling individuals, we hypothesise an effect of menstrual cycle phase on melatonin suppression outcomes.
H0: No effect of menstrual cycle phase on melatonin suppression outcomes.
We believe that the following model described the data:
- Full model: Melatonin AUC relative to dark AUC = β0 +β1 Menstrual phase + β2 (1|participant) + β3 (1|menstrual phase)
- Null model: Melatonin AUC relative to dark AUC = β0 + β1 (1|participant)

The type of BFDA we want to perform in this study is a fixed-n design. This is because we know that we can only have a maximum of n=12 naturally cycling participants for resource and time constraints. Hence, the BFDA can help us to answer this questions:
1. Given a sample size of N=12 and expected population effect size, which Bayes Factors can I expect?
2. What sample size do I need to have to obtain true positive or true negative evidence with a certain probability?

### Fixed-n BFDA workflow
The general workflow we will follow:
1. Generate a full model that you think explains the data, and a related null model
2. Assume a population with certain properties
3. Repeatedly draw random samples from this population
4. Compute the BF for each sample


#### Requirements
- We define a model for the data we are interested in collecting in our experiment. For example y = a + b*x. Let's imagine that y is melatonin suppression response and x is menstrual cycle phase. 
- We define a sample size of n=12
- We assume that a and b have a normal distribution with mean mean_a (5 possible values) and mean_b (5 possible values)
- We assume that the sd of a and the sd of b are fixed, i.e. sd_a = 0.1, sd_b = 0.1
- We also define that x is menstrual cycle phase, so it can only assume 4 values

Model of interest to test CH3a:
melatonin suppression = E2 levels + P4 levels + (E2 + P4 | PID), where E2 = estradiol levels, P4 = progesterone levels, and PID = participant ID.

## Importing the informed parameters
These have been calculated in the previous script (informed_data_simulation.Rmd)
```{r}
library(tidyverse)
library(lmerTest)
library(BayesFactor)

path <- "C:/code/shine_RegisteredReport/power_analysis/bfda/"

informed_parameters <- read.csv(file.path(path, "informed_parameters.csv"))

# Keep only cols of interest
informed_parameters <- informed_parameters %>%
  select(intercept_mean, e2_slope_mean, p4_slope_mean) 

head(informed_parameters)

```

## Defining the parameters for bfda model 
Our full model is:
y = intercept + e2_slope * e2_value + p4_slope * p4_value + noise
```{r}
# Fixed participant number, dictated by resource limitations
n_ids <- 12 

# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)

# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)

# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.2
e2_slope_sd <- 0.2
p4_slope_sd <- 0.2

# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1

# Define number of simulations to run

num_simulations <- 5

# Define threshold for Bayes Factor 
bf_threshold <- 3
```

### Running the simulations and generating BFs
```{r}
set.seed(20250602)

# Store all simulated datasets for later diagnostics or modeling
all_sim_data <- list()

# Create empty data frame to store simulated data 
bfda_simulated_data <- data.frame(intercept_mean = numeric(),
                                  e2_slope_mean = numeric(),
                                  p4_slope_mean = numeric(),
                                  TPR = numeric()
                                  )

# Create an empty dataframe to store all BFs
bfda_all_bfs <- data.frame(
  row = numeric(),
  simulation = numeric(),
  intercept_mean = numeric(),
  e2_slope_mean = numeric(),
  p4_slope_mean = numeric(),
  BF = numeric()
)

# Create a for loop to iterate through the possible combinations of parameters (intercept, e2 slopes, and p4 slope)

for (row in 1:nrow(informed_parameters)) { # looping through each row of the informed_parameter dataframe
    
  # Store BFs for simulations
    bf_list <- numeric(num_simulations)  
    
    # Run simulations: for each combination, repeat the simulation 1000 times 
    for (simulation in seq_len(num_simulations)) {
      
      print(paste0("Row:", row))
      print(paste0("Simulation:", simulation))
      
      # Sample intercept and slopes from normal distribution of defined parameters
      intercept <- rnorm(n_ids, mean = informed_parameters$intercept_mean[row], sd = intercept_sd)
      e2_slope <- rnorm(n_ids, mean = informed_parameters$e2_slope_mean[row], sd = e2_slope_sd)
      p4_slope <- rnorm(n_ids, mean = informed_parameters$p4_slope_mean[row], sd = p4_slope_sd)
      
      # Simulate data for n_ids individuals
      # We are making the assumption that E2 and P4 are independent (for simplicity)
      sim_data <- data.frame(
        id = factor(rep(1:n_ids, each = 4)),
        e2_value = runif((4*n_ids), e2_min_value, e2_max_value),
        p4_value = runif((4*n_ids), p4_min_value, p4_max_value)
        )
      
      # Create values for y by solving the equation and add noise
      sim_data$y <- intercept[sim_data$id] +
        e2_slope[sim_data$id]*sim_data$e2_value + # e2 slope * e2 value for given id
        p4_slope[sim_data$id]*sim_data$p4_value + # p4 slope * p4 value for given id
        rnorm(n_ids*4,mean = 0, sd = 0.3) # noise ~ N(0, sd=0.3), for each experiment 
      
      # Save sim_data for later diagnostics
      all_sim_data[[paste0("row", row, "_sim", simulation)]] <- sim_data
      
      # Check for absence of NAs in the dataset
      if (anyNA(sim_data)) {
        print(sim_data[!complete.cases(sim_data), ])
        stop(sprintf("NA found in sim_data at row %d, simulation %d", row, simulation))
        }
      
      print(paste0("Sim data row",nrow(sim_data))) # print number of rows for sim_data
      

      # Compute Bayes Factor for full model, with predictors being e2 and p4 levels

      bf_full <- BayesFactor::lmBF(y ~ e2_value + p4_value + id + id:e2_value + id:p4_value,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting individual slope and intercept for each id 
      # This function already calculates the ratio between the full model and a model where the intercept is the grand mean
      
    
      # Compute the Bayes Factor for the null model, with predictor being the id variation
      bf_only_intercept <- BayesFactor::lmBF(y ~ id ,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting a different intercept for each id
      # This function calculates the ratio between a model where the intercept is different for each id compared to a model where the intercept in the grand mean 
      
      # Take ratio of these two models, meaning the models where intercept is the grand mean cancel each other out
      # So we are effectively taking a ratio between the full model and a model where the intercept is different for id
      bf_ratio <- bf_full/bf_only_intercept
      
      print(bf_full)
      print(bf_only_intercept)
      print(bf_ratio)
      
      # Extract BF value from bf_ratio
      bf_numeric <- as.numeric(BayesFactor::extractBF(bf_ratio)$bf) 
      bf_list[simulation] <- bf_numeric
      
      # Store each BF with its parameters
      bfda_all_bfs <- rbind(
        bfda_all_bfs,
        data.frame(
        row = row,
        simulation = simulation,
        intercept_mean = informed_parameters$intercept_mean[row],
        e2_slope_mean = informed_parameters$e2_slope_mean[row],
        p4_slope_mean = informed_parameters$p4_slope_mean[row],
        BF = bf_numeric
      )
    )
      
  }
    
  # Compute True Positive Rate (TPR)
  TPR <- sum(bf_list > bf_threshold) / num_simulations
  
  # Store in results
  bfda_simulated_data <- rbind(bfda_simulated_data,
                               data.frame(
                               intercept_mean = informed_parameters$intercept_mean[row],
                               e2_slope_mean = informed_parameters$e2_slope_mean[row],
                               p4_slope_mean = informed_parameters$p4_slope_mean[row],
                               TPR = TPR)
                              )
}


```

# Performing LMM on the sim_data (all of the collected sim_data - with num_simulations = 5)
First, we create a function that tests for model fit (i.e. does the model converge, when we run it with an LMM?)
```{r}
run_model_diagnostics <- function(model_formula, data_list) {
  lapply(names(data_list), function(name) {
    dat <- data_list[[name]]
    
    fit <- tryCatch(
      lmer(model_formula, data = dat),
      error = function(e) return(list(error = e$message, name = name))
    )
    
    if (inherits(fit, "list")) {
      return(fit)  # error info
    }
    
    list(
      name = name,
      is_singular = isSingular(fit),
      convergence_warnings = fit@optinfo$conv$lme4$messages,
      summary = summary(fit)
    )
  })
}

```

# Test model convergence on the all_sim_data
## Start with maximal model
```{r}
model_maximal <- y ~ e2_value + p4_value + (1 + e2_value + p4_value | id)

# Run diagnostics for model_maximal
diag_model_maximal <- run_model_diagnostics(model_maximal, all_sim_data)

# Turning the model diagnostics into a dataframe
diagnostic_overview_maximal <- do.call(rbind, lapply(diag_model_maximal, function(x) {
  if (!is.list(x) || !"name" %in% names(x)) return(NULL)
  data.frame(
    sim_name = x$name,
    is_singular = ifelse("is_singular" %in% names(x), x$is_singular, NA),
    has_convergence_warning = ifelse("convergence_warnings" %in% names(x) && !is.null(x$convergence_warnings), TRUE, FALSE),
    error = ifelse("error" %in% names(x), x$error, NA),
    stringsAsFactors = FALSE
  )
}))

# Checking how many models (in percentage) do converge
total_models_max <- nrow(diagnostic_overview_maximal)

successful_models_max <- diagnostic_overview_maximal %>%
  filter(is_singular == FALSE & has_convergence_warning == FALSE) %>%
  nrow()

percent_converged_max <- (successful_models_max/total_models_max)*100

print(percent_converged_max)
```
This shows that more than only 28% of models do actually converge. Thus, we cannot use the maximal model for our BFDA. We now look at which variable in the random effects explains the least variance. We will have a quick look at the first 10 models to see if we observe a pattern. 
```{r}
diag_model_maximal[1:10]

```
It seems like the variance explained by e2_value and p4_value is very similar. Hence, eliminating the one or the other would not make a big difference. We choose to remove p4_value. 

## Reduced model 1
We remove random slopes for p4
```{r}
model_reduced_1 <- y ~ e2_value + p4_value + (1 + e2_value | id)

# Run diagnostics for model_reduced_1
diag_model_reduced_1 <- run_model_diagnostics(model_reduced_1, all_sim_data)

# Turning the model diagnostics into a dataframe
diagnostic_overview_model_reduced_1 <- do.call(rbind, lapply(diag_model_reduced_1, function(x) {
  if (!is.list(x) || !"name" %in% names(x)) return(NULL)
  data.frame(
    sim_name = x$name,
    is_singular = ifelse("is_singular" %in% names(x), x$is_singular, NA),
    has_convergence_warning = ifelse("convergence_warnings" %in% names(x) && !is.null(x$convergence_warnings), TRUE, FALSE),
    error = ifelse("error" %in% names(x), x$error, NA),
    stringsAsFactors = FALSE
  )
}))

# Checking how many models (in percentage) do converge
total_models_r1 <- nrow(diagnostic_overview_model_reduced_1)

successful_models_r1 <- diagnostic_overview_model_reduced_1 %>%
  filter(is_singular == FALSE & has_convergence_warning == FALSE) %>%
  nrow()

percent_converged_r1 <- (successful_models_r1/total_models_r1)*100

print(percent_converged_r1)
```
This works better, but still only around 50% of all models have converged. The next step is to remove the random slopes altogether, and only allow for a random intercept. 

# Reduced model 2
```{r}
model_reduced_2 <- y ~ e2_value + p4_value + (1 | id)

# Run diagnostics for model_reduced_1
diag_model_reduced_2 <- run_model_diagnostics(model_reduced_2, all_sim_data)

# Turning the model diagnostics into a dataframe
diagnostic_overview_model_reduced_2 <- do.call(rbind, lapply(diag_model_reduced_2, function(x) {
  if (!is.list(x) || !"name" %in% names(x)) return(NULL)
  data.frame(
    sim_name = x$name,
    is_singular = ifelse("is_singular" %in% names(x), x$is_singular, NA),
    has_convergence_warning = ifelse("convergence_warnings" %in% names(x) && !is.null(x$convergence_warnings), TRUE, FALSE),
    error = ifelse("error" %in% names(x), x$error, NA),
    stringsAsFactors = FALSE
  )
}))

# Checking how many models (in percentage) do converge
total_models_r2 <- nrow(diagnostic_overview_model_reduced_2)

successful_models_r2 <- diagnostic_overview_model_reduced_2 %>%
  filter(is_singular == FALSE & has_convergence_warning == FALSE) %>%
  nrow()

percent_converged_r2 <- (successful_models_r2/total_models_r2)*100

print(percent_converged_r2)
```
More than 90% models converge when no random slopes (but a random intercept) is added. Hence, we will use this model for the BFDA. The following code chunks are a repeat of the first BFDA round above, with the exception that the full model has now been reduced to a model without any random slopes but only a random intercept.

```{r}
# Fixed participant number, dictated by resource limitations
n_ids <- 12 

# Select possible values for intercept mean, based on what we know worked
intercept_mean_list <- list(informed_parameters$intercept_mean)

# Select possible values for the slopes (i.e. the betas of the predictors), based on what we know worked
e2_slope_mean_list <- list(informed_parameters$e2_slope_mean)
p4_slope_mean_list <- list(informed_parameters$p4_slope_mean)

# Fix the standard deviations for the intercept and slopes, based on what we know worked
intercept_sd <- 0.2
e2_slope_sd <- 0.2
p4_slope_sd <- 0.2

# Specify values of E2 and P4 (expressed as standardised values between -1 and 1)
e2_min_value <- -1
e2_max_value <- 1
p4_min_value <- -1
p4_max_value <- 1

# Define number of simulations to run

num_simulations <- 5

# Define threshold for Bayes Factor 
bf_threshold <- 3
```

### Running the simulations and generating BFs
```{r}
set.seed(20250602)

# Store all simulated datasets for later diagnostics or modeling
all_sim_data <- list()

# Create empty data frame to store simulated data 
bfda_simulated_data <- data.frame(intercept_mean = numeric(),
                                  e2_slope_mean = numeric(),
                                  p4_slope_mean = numeric(),
                                  TPR = numeric()
                                  )

# Create an empty dataframe to store all BFs
bfda_all_bfs <- data.frame(
  row = numeric(),
  simulation = numeric(),
  intercept_mean = numeric(),
  e2_slope_mean = numeric(),
  p4_slope_mean = numeric(),
  BF = numeric()
)

# Create a for loop to iterate through the possible combinations of parameters (intercept, e2 slopes, and p4 slope)

for (row in 1:nrow(informed_parameters)) { # looping through each row of the informed_parameter dataframe
    
  # Store BFs for simulations
    bf_list <- numeric(num_simulations)  
    
    # Run simulations: for each combination, repeat the simulation 1000 times 
    for (simulation in seq_len(num_simulations)) {
      
      print(paste0("Row:", row))
      print(paste0("Simulation:", simulation))
      
      # Sample intercept and slopes from normal distribution of defined parameters
      intercept <- rnorm(n_ids, mean = informed_parameters$intercept_mean[row], sd = intercept_sd)
      e2_slope <- rnorm(n_ids, mean = informed_parameters$e2_slope_mean[row], sd = e2_slope_sd)
      p4_slope <- rnorm(n_ids, mean = informed_parameters$p4_slope_mean[row], sd = p4_slope_sd)
      
      # Simulate data for n_ids individuals
      # We are making the assumption that E2 and P4 are independent (for simplicity)
      sim_data <- data.frame(
        id = factor(rep(1:n_ids, each = 4)),
        e2_value = runif((4*n_ids), e2_min_value, e2_max_value),
        p4_value = runif((4*n_ids), p4_min_value, p4_max_value)
        )
      
      # Create values for y by solving the equation and add noise
      sim_data$y <- intercept[sim_data$id] +
        e2_slope[sim_data$id]*sim_data$e2_value + # e2 slope * e2 value for given id
        p4_slope[sim_data$id]*sim_data$p4_value + # p4 slope * p4 value for given id
        rnorm(n_ids*4,mean = 0, sd = 0.3) # noise ~ N(0, sd=0.3), for each experiment 
      
      # Save sim_data for later diagnostics
      all_sim_data[[paste0("row", row, "_sim", simulation)]] <- sim_data
      
      # Check for absence of NAs in the dataset
      if (anyNA(sim_data)) {
        print(sim_data[!complete.cases(sim_data), ])
        stop(sprintf("NA found in sim_data at row %d, simulation %d", row, simulation))
        }
      
      print(paste0("Sim data row",nrow(sim_data))) # print number of rows for sim_data
      

      # Compute Bayes Factor for full model, with predictors being e2 and p4 levels

      bf_full <- BayesFactor::lmBF(y ~ e2_value + p4_value + id,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting individual slope and intercept for each id 
      # This function already calculates the ratio between the full model and a model where the intercept is the grand mean
      
    
      # Compute the Bayes Factor for the null model, with predictor being the id variation
      bf_only_intercept <- BayesFactor::lmBF(y ~ id ,
                                   data = sim_data,
                                   whichRandom = "id",
                                   progress = FALSE) # fitting a different intercept for each id
      # This function calculates the ratio between a model where the intercept is different for each id compared to a model where the intercept in the grand mean 
      
      # Take ratio of these two models, meaning the models where intercept is the grand mean cancel each other out
      # So we are effectively taking a ratio between the full model and a model where the intercept is different for id
      bf_ratio <- bf_full/bf_only_intercept
      
      print(bf_full)
      print(bf_only_intercept)
      print(bf_ratio)
      
      # Extract BF value from bf_ratio
      bf_numeric <- as.numeric(BayesFactor::extractBF(bf_ratio)$bf) 
      bf_list[simulation] <- bf_numeric
      
      # Store each BF with its parameters
      bfda_all_bfs <- rbind(
        bfda_all_bfs,
        data.frame(
        row = row,
        simulation = simulation,
        intercept_mean = informed_parameters$intercept_mean[row],
        e2_slope_mean = informed_parameters$e2_slope_mean[row],
        p4_slope_mean = informed_parameters$p4_slope_mean[row],
        BF = bf_numeric
      )
    )
      
  }
    
  # Compute True Positive Rate (TPR)
  TPR <- sum(bf_list > bf_threshold) / num_simulations
  
  # Store in results
  bfda_simulated_data <- rbind(bfda_simulated_data,
                               data.frame(
                               intercept_mean = informed_parameters$intercept_mean[row],
                               e2_slope_mean = informed_parameters$e2_slope_mean[row],
                               p4_slope_mean = informed_parameters$p4_slope_mean[row],
                               TPR = TPR)
                              )
}



```
## Visual check to ensure that we did create random intercepts and slopes for E2 and P4

```{r}
# Plot y vs e2_value coloured by id
ggplot(sim_data, aes(x = e2_value, y = y, color = id)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
  labs(title = "Random slopes and intercept check for E2",
       x = "e2_value",
       y = "Melatonin suppression") +
  theme_minimal()

# Plot y vs p4_value coloured by id
ggplot(sim_data, aes(x = p4_value, y = y, color = id)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = id), linewidth = 0.8) +
  labs(title = "Random slopes and intercept check for P4",
       x = "p4_value",
       y = "Melatonin suppression") +
  theme_minimal()
```

## Checking TPR as a function of parameters

```{r}
# Plot heatmap
library(scales)

ggplot(bfda_simulated_data, aes(x = e2_slope_mean, y = p4_slope_mean)) +
  geom_tile(aes(fill = TPR), colour = "black") +
  scale_fill_gradient(low = "white", high = "darkgreen", name = "TPR") +
  labs(
    title = "True positive rate (TPR) for E2 and P4 slope means combinations",
    x = "E2 slope mean",
    y = "P4 slope mean"
  ) +
   scale_x_continuous(
    breaks = seq(-0.5, 0.5, by = 0.1),
    limits = c(-0.5, 0.5)
  ) +
  scale_y_continuous(
    breaks = seq(-0.5, 0.5, by = 0.1),
    limits = c(-0.5, 0.5)
  ) +
  coord_fixed(ratio = 1) +
  theme_bw() +
  theme(
    aspect.ratio = 1,
    panel.grid = element_blank(),  # clean up grid lines inside tiles
    axis.text = element_text(size = 10),
    axis.title = element_text(size = 12)
  )

```


68
