---
title: "data_simulation"
author: "Carolina Guidolin"
date: "2025-05-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
```


# Using data from Fernandez-Alonso et al (2025) to create set of plasuible distribution values for our model

Model of interest to test CH3a:
melatonin suppression = E2 levels + P4 levels + (E2 | PID) + (P4 | PID), where E2 = estradiol levels, P4 = progesterone levels, and PID = participant ID.

We first import melatonin suppression data to get

1. Define a list of potential distribution for intercept 
2. Define a list of potential distribution for the slope of E2 (first predictor) - mean and SD, with SD = 10% of the mean
3. Define a list of potential distribution for the slope of P4 (second predictor) - mean and SD, with SD = 10% of the mean
4. Define a range for the values of E2 and P4
5. Define noise distribution with mean 0 and SD 5
6. For each combination of the distribution and values of E2 and P4, create fake data y (i.e. melatonin suppression) for that model - for the same combination do this 100 times, meaning for each combination you get 100 values of y
7. Calculate the mean and SD of the fake data of this one y 
8. Compare to Maydel's data and re-iterate - define a criterion for what "good" and "bad" combinations of the parameter distributions (e.g. anything that is + or - 20% away fro mean of Maydel's data)

```{r}
y = intercept + slope1*E2 + slope2*P4 + noise
```
## First, we import data about melatonin suppression values from [Fernandez-Alonso(2025)](https://www.biorxiv.org/content/10.1101/2025.01.15.633125v2.full)

We use this data as reference data to understand the range of possible melatonin suppression values given a light exposure of ~90 melanopic EDI (here condition = "bright light"). This experiment was performed with virtually the same protocol as the one we are designing, i.e. light exposure of same intensity presented at the same circadian time and using the same VR headset system. While most participants in this study did not have a dilated pupil (and in our study all participants will have dilated pupil during light exposure), we still consider these findings to be informative for our sample size calculation. 

```{r}
# Importing data
mlt_data <- read.csv("VR_paper_melatonin_results.csv")

# Calculating summary statistics
mlt_data_summary <- mlt_data %>%
  summarise(mean = mean(mel_supp),
            sd = sd(mel_supp),
            median = median(mel_supp),
            iqr = IQR(mel_supp),
            q1 = quantile(mel_supp, 0.25),
            q3 = quantile(mel_supp, 0.75))
```

This gives us an average melatonin suppression of 33.32±48.28 (1SD), and median 41.57 and Q1 = 18.12 and Q3 = 73.77. The large SD indicate inter-individual variability in melatonin suppression to the same stimulus (i.e. bright light). 

## Given our model of interest, we now start to assign values to the variables in the model
We want to assign a lot of possible values to our predictors, and check how this influences the predicted variable y (melatonin suppression). The goal is to identified a set of predictor values which lead to physiologically-relevant y values, i.e. in line with what observed in the data we already have. Note that we do need to have a range of possible values for E2 and P4. We take values from [Anckaert et al., (2021)](https://pmc.ncbi.nlm.nih.gov/articles/PMC8042396/), who have analysed E2 and P4 levels at various phases on the menstrual cycle. Although they analyse serum levels and not plasma levels, and use immunoassays instead of LC-MS as we plan to, this data is the most informative that we can use for our study (due to lack of reporting of plasma hormone levels across the cycle using LC-MS). The data is expressed in pmol/L for E2 and nmol/L for P4.
- E2 min value (early follicular phase) = 75.5 pmol/L
- E2 max value (peri-ovulatory phase) = 2212 pmol/L
- P4 min value (early follicular phase) = 0.159 nmol/L
- P4 max value (intermediate luteal phase) = 66.5 nmol/L

```{r}
# We start by defining variables of our model 
# Intercept
intercept_mean_list <- seq(0, 100, by = 5)

#E2 slope values
e2_slope_mean_list <- c(
  seq(0.001, 0.009, length.out = 10),  # values in 0.001–0.009
  seq(0.01, 0.09, length.out = 10), # values in 0.01–0.09
  seq(0.1, 0.9, length.out = 10),      # values in 0.1–0.9
  seq(1, 9, length.out = 10),          # values in 1–9
  seq(10, 100, length.out = 10)        # values in 10–100
)

#P4 slope values
p4_slope_mean_list <- c(
  seq(0.001, 0.009, length.out = 10),
  seq(0.01, 0.09, length.out = 10),
  seq(0.1, 0.9, length.out = 10),
  seq(1, 9, length.out = 10),
  seq(10, 100, length.out = 10)
)

# E2 and P4 values (expressed in pmol/L for E2 and nmol/L for P4)
e2_min_value <- 75.5
e2_max_value <- 2212
p4_min_value <- 0.159
p4_max_value <- 66.5
num_simulations <- 100

# Extract known mlt values from mlt_data_summary
mlt_data_mean <- mlt_data_summary$mean
mlt_data_sd <- mlt_data_summary$sd
mlt_data_median <- mlt_data_summary$median
mlt_data_q1 <- mlt_data_summary$q1
mlt_data_q3 <- mlt_data_summary$q3
```

## Create for loop 
```{r}
# Create empty data frame to store results
simulated_data_results <- data.frame(intercept_mean = numeric(),
                                e2_slope_mean = numeric(),
                                p4_slope_mean = numeric(),
                                mean_y = numeric(),
                                sd_y = numeric(),
                                accepted = factor())

for (intercept_mean in intercept_mean_list) { # loop over possible intercept means
  for (e2_slope_mean in e2_slope_mean_list) { # loop over possible e2 slope means
    for (p4_slope_mean in p4_slope_mean_list) { # loop over possible p4 slope means
      
      # Simulate 100 samples of y for each parameter combination
      y <- numeric(num_simulations)
      for (simulation in seq_len(num_simulations)) {
        
        # Sample E2 and P4 from uniform distribution
        e2_value <- runif(1, e2_min_value, e2_max_value)
        p4_value <- runif(1, p4_min_value, p4_max_value)
        
        # Centering E2 and P4 - needed because the given values are on different scales
        e2_centered <- e2_value - mean(c(e2_min_value, e2_max_value))
        p4_centered <- p4_value - mean(c(p4_min_value, p4_max_value))
        
        # Noise ~ N(0, 5)
        noise <- rnorm(1, mean = 0, sd = 5)
        
        # Intercept ~ N(intercept_mean, 10% of intercept_mean)
        intercept <- rnorm(1, mean = intercept_mean, sd = 0.1 * intercept_mean)
        
        # Slopes ~ N(slope_mean, 10% of slope_mean)
        e2_slope <- rnorm(1, mean = e2_slope_mean, sd = 0.1 * e2_slope_mean)
        p4_slope <- rnorm(1, mean = p4_slope_mean, sd = 0.1 * p4_slope_mean)
        
        
        # Model
        y[simulation] <- intercept + e2_slope*e2_centered + p4_slope*p4_centered + noise
      
        }
    
    # Calculate summary stats of y
    mean_y <- mean(y)
    sd_y <- sd(y)
      
    # Determine if the mean of y is within q1 and q3 of the known melatonin data 
    accepted <- ifelse(mean_y >= mlt_data_q1 & mean_y <= mlt_data_q3, "yes", "no")
      
    # Store results
    simulated_data_results <- rbind(simulated_data_results,
                               data.frame(intercept_mean = intercept_mean,
                                          e2_slope_mean = e2_slope_mean,
                                          p4_slope_mean = p4_slope_mean,
                                          mean_y = mean_y,
                                          sd_y = sd_y,
                                          accepted = factor(accepted)))
    }
  }
}

simulated_data_results_summary <- simulated_data_results %>%
  filter(accepted == "yes") %>%
  summarise(min_intercept = min(intercept_mean),
            max_intercept = max(intercept_mean),
            min_e2 = min(e2_slope_mean),
            median_e2 = median(e2_slope_mean),
            max_e2 = max(e2_slope_mean),
            min_p4 = min(p4_slope_mean),
            median_p4 = median(p4_slope_mean),
            max_p4 = max(p4_slope_mean))
    

# Save results as a csv that we can look at 
#write.csv(fake_data_results, "fake_data_results.csv", row.names = FALSE)


```

## Visualise relationships between simulated variables for intercept and slopes 
```{r}
GGally::ggpairs(simulated_data_results[simulated_data_results$accepted == "yes", 
                                    c("intercept_mean", "e2_slope_mean", "p4_slope_mean")])
```
## Other visualisation, for each parameter of interest
```{r}
# Filter dataset to only accept values within mlt_data q1 and q3
accepted_params <- simulated_data_results %>%
  filter(accepted == "yes")

library(ggplot2)

ggplot(accepted_params, aes(x = intercept_mean)) +
  geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
  theme_minimal()

ggplot(accepted_params, aes(x = e2_slope_mean)) +
  geom_histogram(binwidth = 0.1, fill = "salmon", color = "black") +
  theme_minimal()

ggplot(accepted_params, aes(x = p4_slope_mean)) +
  geom_histogram(binwidth = 0.1, fill = "lightgreen", color = "black") +
  theme_minimal()

# Get 10th and 90th percentiles to define "central" range
intercept_range <- quantile(accepted_params$intercept_mean, probs = c(0.1, 0.9))
e2_slope_range <- quantile(accepted_params$e2_slope_mean, probs = c(0.1, 0.9))
p4_slope_range <- quantile(accepted_params$p4_slope_mean, probs = c(0.1, 0.9))
```


